val0, val1, ..., valn, cls
-> 	cls, 1
		-> cls, cls_count
	0 @ val0 @ cls, 1
		-> 0 @ val0, cls @ count_for_val0_of_attr_0	
		-> 0, val0 @ total_row_val0 @ entropy @ class_with_max_probability

After MapReduce:
	"cls0", count_cls0	
	"cls1", count_cls1	
	"cls2", count_cls2	
	...

	0, val00 @ total_row_val00 @ entropy_00 @ class_with_max_probability
	0, val01 @ total_row_val01 @ entropy_01 @ class_with_max_probability
	1, val10 @ total_row_val10 @ entropy_10 @ class_with_max_probability
	...

Then:
	total = count_cls0 + ...
	counts = { "cls0": count_cls0, ... }
	attrs = { 0: [ ... ],
			  1: [ ... ],...
			  }
	
	before_split_gain = - sum(p * logp) with p = count_cls0 / total,...
	for attr in attrs:
		gain = before_split_gain - sum(p * entropy)
		save best_split = best_gain, attr
	
	if on the last attribute:
		write out the rule
	
	for split in attr:
		if entropy is small: stop and write out the rule
		else:
			continue building tree by omitting the split -> this only works for branching into multiple branch and for categorical variables

